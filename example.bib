@Inbook{1,
author="Ostrovsky, Mikhail",
editor="Skjeltorp, Arne T.
and Belushkin, Alexander V.",
chapter="Evolution of Vision",
title="Evolution from Cellular to Social Scales",
year="2008",
publisher="Springer Netherlands",
address="Dordrecht",
pages="169--183",
isbn="978-1-4020-8761-5",
doi="10.1007/978-1-4020-8761-5_12",
url="http://dx.doi.org/10.1007/978-1-4020-8761-5_12"
}

@article{2,
author = {Thoermer, Claudia and Sodian, Beate}, 
title = {Preverbal infants' understanding of referential gestures},
volume = {21}, 
number = {63}, 
pages = {245-264}, 
year = {2001}, 
doi = {10.1177/014272370102106303}, 
abstract ={In a short-term longitudinal study, 10- and 12-month-old infants' (N = 43) comprehension of referential gestures (gaze- and point- comprehension) was assessed independently in an attention- following task, and a preference-for-novelty task, measuring infants' encoding of actor-goal-relations (cf. Woodward 1998). Consistent with previous findings, marked developmental progress was found in gaze- and point-following between 10 and 12 months, with 12-month-olds approaching ceiling. In contrast, neither 10- nor 12-month-olds responded to a change in relation between actor and object, when the actor looked at or looked and pointed at the target object, whereas at 12 months of age they did, when the actor both looked at and reached for the target. These findings indicate that infants' ability to follow communicative gestures is not initially accompanied by an understanding of the intentional relation between communicator and referent independently of the communicative situation. The findings support the role of early pragmatic scaffolding in caretaker-infant interaction in building such an understanding.}, 
URL = {http://fla.sagepub.com/content/21/63/245.abstract}, 
eprint = {http://fla.sagepub.com/content/21/63/245.full.pdf+html}, 
journal = {First Language} 
}

@article{3,
    author = {Kleinke, Chris L.},
    citeulike-article-id = {1890226},
    journal = {Psychological Bulletin},
    keywords = {culture, eye, gaze},
    number = {1},
    pages = {78--100},
    posted-at = {2007-11-09 15:57:53},
    priority = {5},
    title = {{Gaze and Eye Contact: A Research Review}},
    volume = {100},
    year = {1986}
}

@article{4,
author = {Macdonald, Ross G. and Tatler, Benjamin W.},
title = {Do as eye say: Gaze cueing and language in a real-world social interaction},
journal = {Journal of Vision},
volume = {13},
number = {4},
pages = {6},
year = {2013},
doi = {10.1167/13.4.6},
URL = {http://dx.doi.org/10.1167/13.4.6},
eprint = {/data/Journals/JOV/932809/i1534-7362-13-4-6.pdf}
}

@article{5,
    abstract = {{Four studies investigated whether and when infants connect information about an actor's affect and perception to their action. Arguably, this may be a crucial way in which infants come to recognize the intentional behaviors of others. In Study 1 an actor grasped one of two objects in a situation where cues from the actor's gaze and expression could serve to determine which object would be grasped, specifically the actor first looked at and emoted positively about one object but not the other. Twelve-month-olds, but not 8-month-olds, recognized that the actor was likely to grasp the object which she had visually regarded with positive affect. Studies 2, 3, and 4 replicated the main finding from Study 1 with 12- and 14-month-olds and included several contrasting conditions and controls. These studies provide evidence that the ability to use information about an adult's direction of gaze and emotional expression to predict action is both present, and developing at the end of the first year of life.}},
    author = {Phillips, Ann T. and Wellman, Henry M. and Spelke, Elizabeth S.},
    citeulike-article-id = {6350467},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/12086713},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=12086713},
    issn = {0010-0277},
    journal = {Cognition},
    keywords = {cp\_prosem, development, infants, intentionality, social\_cognition, theory\_of\_mind},
    month = aug,
    number = {1},
    pages = {53--78},
    pmid = {12086713},
    posted-at = {2009-12-10 19:02:18},
    priority = {0},
    title = {{Infants' ability to connect gaze and emotional expression to intentional action.}},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/12086713},
    volume = {85},
    year = {2002}
}

@Article{6,
author="Campos, Joana
and Alves-Oliveira, Patr{\'i}cia
and Paiva, Ana",
title="Looking for Conflict: Gaze Dynamics in a Dyadic Mixed-Motive Game",
journal="Autonomous Agents and Multi-Agent Systems",
year="2015",
volume="30",
number="1",
pages="112--135",
abstract="The way gaze cues are used in social interactions is by no means irrelevant because they are fundamentally important for understanding social interactions. In this paper, we argue that social conflict is a form of relating and that gaze clues are critical to understanding the underlying cognitive processes in this phenomenon. To learn more about conflict, we created an experimental setting that reduces real life to a mixed-motive game. We analyse the gaze patterns of 22 10- to 12-year-old children in specific game moments that could have been conductive to conflict. Our aim is to understand how subtle forms of conflict unfold, by analysing micro-level behaviours and establishing a link to high-level psychological constructs. Their gazes show that children are being more competitive or cooperative at different stages of the game. Children tend to avoid confrontation by averting face-directed gazes when they are asking for larger profits, and they gaze longer to attempt to persuade the other child.",
issn="1573-7454",
doi="10.1007/s10458-015-9282-8",
url="http://dx.doi.org/10.1007/s10458-015-9282-8"
}

@INPROCEEDINGS{7, 
author={Dongheng Li and D. Winfield and D. J. Parkhurst}, 
booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops}, 
title={Starburst: A hybrid algorithm for video-based eye tracking combining feature-based and model-based approaches}, 
year={2005}, 
pages={79-79}, 
keywords={Algorithm design and analysis;Availability;Computer interfaces;Computer vision;Costs;Hardware;Human computer interaction;Keyboards;Open source software;Tracking}, 
doi={10.1109/CVPR.2005.531}, 
ISSN={2160-7508}, 
month={June},}


@Article{8,
AUTHOR = {Lee, Ji Woo and Heo, Hwan and Park, Kang Ryoung},
TITLE = {A Novel Gaze Tracking Method Based on the Generation of Virtual Calibration Points},
JOURNAL = {Sensors},
VOLUME = {13},
YEAR = {2013},
NUMBER = {8},
PAGES = {10802},
URL = {http://www.mdpi.com/1424-8220/13/8/10802},
PubMedID = {23959241},
ISSN = {1424-8220},
ABSTRACT = {Most conventional gaze-tracking systems require that users look at many points during the initial calibration stage, which is inconvenient for them. To avoid this requirement, we propose a new gaze-tracking method with four important characteristics. First, our gaze-tracking system uses a large screen located at a distance from the user, who wears a lightweight device. Second, our system requires that users look at only four calibration points during the initial calibration stage, during which four pupil centers are noted. Third, five additional points (virtual pupil centers) are generated with a multilayer perceptron using the four actual points (detected pupil centers) as inputs. Fourth, when a user gazes at a large screen, the shape defined by the positions of the four pupil centers is a distorted quadrangle because of the nonlinear movement of the human eyeball. The  gaze-detection accuracy is reduced if we map the pupil movement area onto the screen area using a single transform function. We overcame this problem by calculating the gaze position based on multi-geometric transforms using the five virtual points and the four actual points. Experiment results show that the accuracy of the proposed method is better than that of other methods.},
DOI = {10.3390/s130810802}
}





@INPROCEEDINGS{9,
    author = {Jan Ciger and Bruno Herbelin and Daniel Thalmann},
    title = {Evaluation of Gaze Tracking Technology for Social Interaction in Virtual Environments},
    booktitle = {In Proc. of the 2nd Workshop on Modeling and Motion Capture Techniques for Virtual Environments (CAPTECH'04},
    year = {2004},
    pages = {9--11}
}

@INPROCEEDINGS{10, 
author={K. A. F. Mora and J. M. Odobez}, 
booktitle={2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops}, 
title={Gaze estimation from multimodal Kinect data}, 
year={2012}, 
pages={25-30}, 
keywords={image motion analysis;interactive devices;mesh generation;object tracking;pose estimation;3D mesh tracking;3D space;Kinect device;depth sensing;eye-in-head gaze directional information;gaze estimation;head motion;head pose tracking;image rectification scheme;multimodal Kinect data;multimodal method;visual data;Estimation;Face;Magnetic heads;Solid modeling;Vectors;Visualization}, 
doi={10.1109/CVPRW.2012.6239182}, 
ISSN={2160-7508}, 
month={June},}

@book{11,
  title={Lectures on Quaternions},
  author={Hamilton, W.R.},
  url={https://books.google.com.br/books?id=TCwPAAAAIAAJ},
  year={1853}
}

@book{12,
title = {Novi commentarii Academiae Scientiarum Imperialis Petropolitanae. },
volume = {t.1 (1747-1748)},
copyright = {NOT_IN_COPYRIGHT},
url = {http://www.biodiversitylibrary.org/item/38631},
note = {http://www.biodiversitylibrary.org/bibliography/9527},
publisher = {Petropolis,Typis Academiae Scientarum,},
author = {Imperatorskai︠a︡ akademīi︠a︡ nauk (Russia) and Imperatorskai︠a︡ akademīi︠a︡ nauk i khudozhestv (Russia)},
year = {1747-1748},
pages = {628},
keywords = {5.06(47.4)S3|Science|},
}

@inproceedings{13,
address = "Berkeley, Calif.",
author = "MacQueen, J.",
booktitle = "Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Statistics",
pages = "281--297",
publisher = "University of California Press",
title = "Some methods for classification and analysis of multivariate observations",
url = "http://projecteuclid.org/euclid.bsmsp/1200512992",
year = "1967"
}

@article {14,
author = {Leekam, Susan R. and Hunnisett, Emma and Moore, Chris},
title = {Targets and Cues: Gaze-following in Children with Autism},
journal = {Journal of Child Psychology and Psychiatry},
volume = {39},
number = {7},
publisher = {Blackwell Publishers Ltd.},
issn = {1469-7610},
url = {http://dx.doi.org/10.1111/1469-7610.00398},
doi = {10.1111/1469-7610.00398},
pages = {951--962},
keywords = {Autism, attention, nonverbal communication, gaze-following, joint attention},
year = {1998},
}

@inproceedings{15,
 author = {Xiong, Xuehan and Liu, Zicheng and Cai, Qin and Zhang, Zhengyou},
 title = {Eye Gaze Tracking Using an RGBD Camera: A Comparison with a RGB Solution},
 booktitle = {Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct Publication},
 series = {UbiComp '14 Adjunct},
 year = {2014},
 isbn = {978-1-4503-3047-3},
 location = {Seattle, Washington},
 pages = {1113--1121},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/2638728.2641694},
 doi = {10.1145/2638728.2641694},
 acmid = {2641694},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {HCI, Kinect, RGBD sensor, RGBD-sensor-based eye gaze tracking, eye gaze, gaze and eye movement analysis methods, multi-modal sensor fusion, pervasive eye-based interaction},
}


